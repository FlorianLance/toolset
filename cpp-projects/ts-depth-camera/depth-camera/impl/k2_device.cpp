
// /*******************************************************************************
// ** Toolset-ts-depth-camera                                                    **
// ** MIT License                                                                **
// ** Copyright (c) [2018] [Florian Lance]                                       **
// **                                                                            **
// ** Permission is hereby granted, free of charge, to any person obtaining a    **
// ** copy of this software and associated documentation files (the "Software"), **
// ** to deal in the Software without restriction, including without limitation  **
// ** the rights to use, copy, modify, merge, publish, distribute, sublicense,   **
// ** and/or sell copies of the Software, and to permit persons to whom the      **
// ** Software is furnished to do so, subject to the following conditions:       **
// **                                                                            **
// ** The above copyright notice and this permission notice shall be included in **
// ** all copies or substantial portions of the Software.                        **
// **                                                                            **
// ** THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR **
// ** IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,   **
// ** FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL    **
// ** THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER **
// ** LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING    **
// ** FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER        **
// ** DEALINGS IN THE SOFTWARE.                                                  **
// **                                                                            **
// ********************************************************************************/

// #include "k2_device.hpp"

// // std
// #include <bitset>
// #include <chrono>
// #include <thread>
// #include <limits>
// #include <algorithm>
// #include <execution>
// #include <iostream>
// #include <fstream>
// #include <numeric>

// // windows
// #include <Ole2.h>

// // kinect
// #include <Kinect.h>

// // opencv
// #include "opencv2/core.hpp"
// #include "opencv2/imgproc/imgproc.hpp"

// // turbojpeg
// #include <turbojpeg.h>

// // local
// #include "utility/benchmark.hpp"
// #include "utility/logger.hpp"
// #include "data/fastpfor_encoding.hpp"


// using namespace tool;
// using namespace tool::cam;
// using namespace tool::geo;
// using namespace std::chrono_literals;


// struct K2Device::Impl{

//     bool cameraInitialized = false;

//     bool colorFrameInfosInitialized = false;
//     float colorFovDiago  = 0.f;
//     float colorFovHori   = 0.f;
//     float colorFovVerti  = 0.f;
//     int colorWidth = 0;
//     int colorHeight = 0;
//     unsigned int colorLengthInPixels;
//     unsigned int colorBytesPerPixel;

//     bool depthFrameInfosInitialized = false;
//     float depthFovDiago  = 0.f;
//     float depthFovHori   = 0.f;
//     float depthFovVerti  = 0.f;
//     int depthWidth = 0;
//     int depthHeight = 0;
//     unsigned int depthLengthInPixels;
//     unsigned int depthBytesPerPixel;

//     // source
//     DWORD frameSource = 0;
//     // frames
//     IColorFrame *colorframe = nullptr;
//     IDepthFrame *depthFrame = nullptr;
//     IInfraredFrame *infraFrame = nullptr;
//     ILongExposureInfraredFrame *longExposureInfraFrame = nullptr;
//     IBodyFrame *bodyFrame = nullptr;
//     // frames references
//     IMultiSourceFrame *multiSouceFrame = nullptr;
//     IColorFrameReference *colorFrameRef = nullptr;
//     IDepthFrameReference *depthFrameRef = nullptr;
//     IInfraredFrameReference *infraFrameRef = nullptr;
//     ILongExposureInfraredFrameReference *longExposureInfraFrameRef = nullptr;
//     IBodyFrameReference *bodyFrameRef = nullptr;

//     // kinect
//     K2FrameRequest mode = K2FrameRequest::undefined;
//     IKinectSensor* sensor = nullptr;            // Kinect sensor
//     IMultiSourceFrameReader* reader = nullptr;  // Kinect data source
//     ICoordinateMapper* mapper = nullptr;        // Converts between depth, color, and 3d coordinate
//     CameraIntrinsics camIntrinsics;

//     // mapping
//     uint32_t cameraSpaceTableLength = 0;
//     PointF* cameraSpaceTable = nullptr;
//     std::vector<ColorSpacePoint> depth2rgb;   // Maps depth pixels to rgb pixels
//     std::vector<bool> validityDepth2Rgb;

//     // indices
//     std::vector<size_t> indicesRawColors;
//     std::vector<size_t> indicesDepths;
//     std::vector<size_t> indicesDepthsWithoutBorders;
//     std::vector<size_t> indicesDepthToColor;

//     std::vector<std::pair<size_t, size_t>> indices2dDepths;
// //    std::vector<int> indicesDepth2Rgb;

//     // depth/cloud
//     std::vector<bool> depthMask;
//     std::unique_ptr<std::array<Pt3f, k2_depth_count>> depthDataTemporal = nullptr;
//     cv::Mat binaryDepth;
//     cv::Mat erodedBinaryDepth;
//     data::FastPForEncoder depthCompressor;
//     K2CloudDataUP cloudData  = nullptr;
//     unsigned short* depthBuffer = nullptr;
//     unsigned int depthBufferSize = 0;
//     int previousSumDepthValues = 0;

//     // color
//     tjhandle jpegCompressor;
//     K2RgbDataUP colorData          = nullptr;
//     K2RgbDataUP processedColorData = nullptr;
//     unsigned char *tjCompressedImage = nullptr;

//     // bodiess
//     // std::unordered_map<std::uint64_t, std::uint64_t> idBodies;

//     // frames
//     std::uint32_t currentFrame = 0;
//     std::unique_ptr<K2Frame> processedFrame = nullptr;

//     Impl(){

//         // init compressor
//         jpegCompressor = tjInitCompress();

//         depthDataTemporal = std::make_unique<std::array<Pt3f, k2_depth_count>>();


//         depth2rgb.resize(k2_depth_count);
//         validityDepth2Rgb.resize(k2_depth_count);

//         indicesDepths.resize(k2_depth_count);
//         std::iota(std::begin(indicesDepths), std::end(indicesDepths), 0);

//         // ?
//         indicesDepthsWithoutBorders.resize((k2_depth_width-2)*(k2_depth_height-2));
//         size_t count = 0;
//         for(size_t ii = 0; ii < k2_depth_height; ++ii){
//             for(size_t jj = 0; jj < k2_depth_width; ++jj){
//                 if(ii > 0 && ii < k2_depth_height-1 && jj > 0 && jj < k2_depth_width-1 ){
//                     indicesDepthsWithoutBorders.emplace_back(count);
//                 }
//                 ++count;
//             }
//         }

//         size_t id = 0;
//         indices2dDepths.resize(k2_depth_count);
//         for(size_t ii = 0; ii < k2_depth_height; ++ii){
//             for(size_t jj = 0; jj < k2_depth_width; ++jj){
//                 indices2dDepths[id++] = std::make_pair(jj,ii); // (0-width / 0-height)
//             }
//         }
//         indicesDepthToColor.resize(k2_depth_count);
// //        indicesDepth2Rgb.resize(kinect2_depth_count);

//         depthMask.resize(k2_depth_count);

//         indicesRawColors.resize(k2_raw_color_data_size/4);
//         std::iota(std::begin(indicesRawColors), std::end(indicesRawColors), 0);
//         binaryDepth         =   cv::Mat(cv::Size(k2_depth_width, k2_depth_height), CV_8U);
//         erodedBinaryDepth   =   cv::Mat(cv::Size(k2_depth_width, k2_depth_height), CV_8U);

//         // final data
//         colorData = std::make_unique<K2RgbData>();
//         cloudData = std::make_unique<K2CloudData>();
//         processedColorData      = std::make_unique<K2RgbData>();

//         // frame
//         processedFrame = std::make_unique<K2Frame>(true);
//     }
// };

// bool check_func_sucess(HRESULT res){
//     return res >= 0;
// }

// K2Device::K2Device() : m_p(std::make_unique<Impl>()){
//     Log::message("Init kinect2");
// }

// K2Device::~K2Device(){

//     // camera
//     close();


//     if(m_p->tjCompressedImage != nullptr){
//         tjFree(m_p->tjCompressedImage);
//     }

//     // compression
//     tjDestroy(m_p->jpegCompressor);

//     // get map table
//     if(m_p->cameraSpaceTable != nullptr){
//         delete m_p->cameraSpaceTable;
//     }
// }

// void K2Device::close(){

//     // close sensor
//     if(m_p->sensor != nullptr){
//         m_p->sensor->Close();
//     }

//     // clean mapper
//     if (m_p->mapper != nullptr){
//         m_p->mapper->Release();
//         m_p->mapper = nullptr;
//     }

//     // clean reader
//     if (m_p->reader != nullptr){
//         m_p->reader->Release();
//         m_p->reader = nullptr;
//     }

//     // clean sensor
//     if (m_p->sensor != nullptr){
//         m_p->sensor->Release();
//         m_p->sensor = nullptr;
//     }
//     m_p->cameraInitialized = false;
//     m_p->mode = K2FrameRequest::undefined;
// }



// bool K2Device::acquire_multi_sources_frame(){

//     m_p->multiSouceFrame = nullptr;

//     using namespace std::chrono;

//     auto timeStart = high_resolution_clock::now();

//     bool get = true;
//     while(get){
//         auto ret = m_p->reader->AcquireLatestFrame(&m_p->multiSouceFrame);
//         if(ret == E_PENDING){
//             auto currenTime = duration_cast<milliseconds>(high_resolution_clock::now() - timeStart).count();
//             if(currenTime > 3000){
//                 Log::error("Failed: AcquireLatestFrame still pending");
//                 return false;
//             }
//             continue;
//         }else if(!check_func_sucess(ret)){
//             Log::error("Failed: AcquireLatestFrame");
//             return false;
//         }
//         break;
//     }


//     return true;
// }

// bool K2Device::acquire_color_frame(){

//     if(!check_func_sucess(m_p->multiSouceFrame->get_ColorFrameReference(&m_p->colorFrameRef))){
//         Log::warning("Fail get_ColorFrameReference");
//         return false;
//     }


//     auto ret = m_p->colorFrameRef->AcquireFrame(&m_p->colorframe);
//     if(!check_func_sucess(ret)){
//         return false;
//     }


//     if(!m_p->colorFrameInfosInitialized){

//         IFrameDescription *f= nullptr;
//         if(check_func_sucess(m_p->colorframe->get_FrameDescription(&f))){
//             f->get_DiagonalFieldOfView(&m_p->colorFovDiago);
//             f->get_HorizontalFieldOfView(&m_p->colorFovHori);
//             f->get_VerticalFieldOfView(&m_p->colorFovVerti);
//             f->get_Width(&m_p->colorWidth);
//             f->get_Height(&m_p->colorHeight);
//             f->get_LengthInPixels(&m_p->colorLengthInPixels);
//             f->get_BytesPerPixel(&m_p->colorBytesPerPixel);

//         }
//         m_p->colorFrameInfosInitialized = true;
//         // Log::message(QSL("Color FOV: ") % QString::number(m_p->colorFovDiago) % QSL(" ") % QString::number(m_p->colorFovHori) % QSL(" ") % QString::number(m_p->colorFovVerti));
//         // Log::message(QSL("Color Lengths: ") % QString::number(m_p->colorWidth) % QSL(" ") % QString::number(m_p->colorHeight) % QSL(" ") % QString::number(m_p->colorLengthInPixels)% QSL(" ") % QString::number(m_p->colorBytesPerPixel));
//     }

//     return true;
// }

// bool K2Device::acquire_depth_frame(){

//     if(!check_func_sucess(m_p->multiSouceFrame->get_DepthFrameReference(&m_p->depthFrameRef))){
//         Log::warning("Fail get_DepthFrameReference");
//         return false;
//     }

//     auto ret = m_p->depthFrameRef->AcquireFrame(&m_p->depthFrame);
//     if(!check_func_sucess(ret)){
//         Log::warning("Fail to acquire depth frame");
//         return false;
//     }

//     if(!m_p->depthFrameInfosInitialized){

//         IFrameDescription *f= nullptr;
//         if(check_func_sucess(m_p->depthFrame->get_FrameDescription(&f))){
//             f->get_DiagonalFieldOfView(&m_p->depthFovDiago);
//             f->get_HorizontalFieldOfView(&m_p->depthFovHori);
//             f->get_VerticalFieldOfView(&m_p->depthFovVerti);
//             f->get_Width(&m_p->depthWidth);
//             f->get_Height(&m_p->depthHeight);
//             f->get_LengthInPixels(&m_p->depthLengthInPixels);
//             f->get_BytesPerPixel(&m_p->depthBytesPerPixel);
//         }

//         m_p->depthFrameInfosInitialized = true;
//         // Log::message(QSL("Depth FOV: ") % QString::number(m_p->depthFovDiago) % QSL(" ") % QString::number(m_p->depthFovHori) % QSL(" ") % QString::number(m_p->depthFovVerti));
//         // Log::message(QSL("Depth Lengths: ") % QString::number(m_p->depthWidth) % QSL(" ") % QString::number(m_p->depthHeight) % QSL(" ") % QString::number(m_p->depthLengthInPixels)% QSL(" ") % QString::number(m_p->colorBytesPerPixel));
//     }


//     return true;
// }

// bool K2Device::acquire_infra_frame(){

//     if(!check_func_sucess(m_p->multiSouceFrame->get_InfraredFrameReference(&m_p->infraFrameRef))){
//          Log::warning("Fail get_InfraredFrameReference");
//         return false;
//     }
//     if(!check_func_sucess(m_p->infraFrameRef->AcquireFrame(&m_p->infraFrame))){
//         return false;
//     }

//     return true;
// }

// bool K2Device::acquire_long_exposure_infra_frame(){

//     if(!check_func_sucess(m_p->multiSouceFrame->get_LongExposureInfraredFrameReference(&m_p->longExposureInfraFrameRef))){
//          Log::warning("Fail get_LongExposureInfraredFrameReference");
//         return false;
//     }
//     if(!check_func_sucess(m_p->longExposureInfraFrameRef->AcquireFrame(&m_p->longExposureInfraFrame))){
//         return false;
//     }
//     return true;
// }

// bool K2Device::acquire_body_frame(){

//     if(!check_func_sucess(m_p->multiSouceFrame->get_BodyFrameReference(&m_p->bodyFrameRef))){
//          Log::warning("Fail get_BodyFrameReference");
//         return false;
//     }
//     if(!check_func_sucess(m_p->bodyFrameRef->AcquireFrame(&m_p->bodyFrame))){
//         return false;
//     }

//     return true;
// }


// bool K2Device::open(K2FrameRequest m){

//     // initialize sensor
//     if(!m_p->cameraInitialized){
//         if(!check_func_sucess(GetDefaultKinectSensor(&m_p->sensor))){
//             Log::error("Failed get default kinect sensor");
//             return false;
//         }

//         if (m_p->sensor == nullptr) {
//             Log::error("Failed opening sensor");
//             return false;
//         }

//         if(!check_func_sucess(m_p->sensor->Open())){
//             Log::error("Cannot open kinect");
//             return false;
//         }

//         if(!check_func_sucess(m_p->sensor->get_CoordinateMapper(&m_p->mapper))){
//             Log::error("Fail get coordinate mapper");
//             return false;
//         }
//         m_p->cameraInitialized = true;
//     }

//     if(m_p->mode == m){
//         return true; // nothing to do
//     }else{
//         // update current mode
//         m_p->mode = m;
//     }

//     // init frame source
//     m_p->frameSource = 0;
//     if(color_channel_required(m)){
//         m_p->frameSource |= FrameSourceTypes::FrameSourceTypes_Color;
//     }
//     if(depth_channel_required(m)){
//         m_p->frameSource |= FrameSourceTypes::FrameSourceTypes_Depth;
//     }
//     if(infra_channel_required(m)){
//         m_p->frameSource |= FrameSourceTypes::FrameSourceTypes_Infrared;
//     }
//     if(long_infra_channel_required(m)){
//         m_p->frameSource |= FrameSourceTypes::FrameSourceTypes_LongExposureInfrared;
//     }
//     m_p->frameSource |= FrameSourceTypes::FrameSourceTypes_Body;

//     // reset data
//     std::fill(std::begin(*m_p->colorData), std::end(*m_p->colorData), Pt3<std::uint8_t>{0,0,0});
//     std::fill(std::begin(*m_p->cloudData), std::end(*m_p->cloudData), Pt3f{});
//     std::fill(std::begin(m_p->depthMask), std::end(m_p->depthMask), false);

//     // open frame source
//     if(!check_func_sucess(m_p->sensor->OpenMultiSourceFrameReader(m_p->frameSource, &m_p->reader))){
//         Log::error("Failed: OpenMultiSourceFrameReader");
//         return false;
//     }

//     return true;
// }


// std::optional<K2Frame> K2Device::get_kinect_data() {

//     if(m_p->reader == nullptr){
//         Log::error("Kinect not opened");
//         return {};
//     }

//     Bench::start("Kinect2::get_kinect_data"sv);
//     Bench::start("Kinect2::acquire_multi_sources_frame"sv);

//     // update frame mode and id
//     m_p->processedFrame->mode = m_p->mode;
//     m_p->processedFrame->frameId = m_p->currentFrame;

//     // get data
//     if(!acquire_multi_sources_frame()){
//         clean_frame();
//         return {};
//     }

//     m_p->processedFrame->timeStampGetFrame = std::chrono::high_resolution_clock::now().time_since_epoch().count();
//     Bench::stop();

//     // store intrinsics
//     if(m_p->processedFrame->intrinsics.size() == 0){
//         m_p->processedFrame->intrinsics = intrinsics();
//     }

//     Bench::start("Kinect2::get_depth_data"sv);
//     // # depth
//     if(depth_channel_required(m_p->mode)){
//         if(acquire_depth_frame()){
//             if(!get_depth_data()){
//                 clean_frame();
//                 return {};
//             }
//         }else{
//             clean_frame();
//             return {};
//         }
//     }
//     Bench::stop();
//     Bench::start("Kinect2::get_color_data"sv);
//     // # color
//     if(color_channel_required(m_p->mode)){
//         if(acquire_color_frame()){
//             get_color_data();
//         }else{
//             clean_frame();
//             return {};
//         }
//     }
//     Bench::stop();
//     Bench::start("Kinect2::get_infra_data"sv);
//     // # infra
//     if(infra_channel_required(m_p->mode)){
//         if(acquire_infra_frame()){
//             get_infra_data();
//         }else{
//             clean_frame();
//             return {};
//         }
//     }
//     Bench::stop();
//     Bench::start("Kinect2::get_long_exposure_infra_data"sv);
//     // # long exposure infra
//     if(long_infra_channel_required(m_p->mode)){
//         if(acquire_long_exposure_infra_frame()){
//             get_long_exposure_infra_data();
//         }else{
//             clean_frame();
//             return {};
//         }
//     }
//     Bench::stop();
//     Bench::start("Kinect2::get_body_data"sv);
//     // # body
//     if(body_channel_required(m_p->mode)){
//         if(acquire_body_frame()){
//             get_body_data();
//         }
//     }
//     Bench::stop();
//     Bench::start("Kinect2::post_computing_depth_data"sv);

//     // post computing data
//     if(depth_channel_required(m_p->mode)){
//         post_computing_depth_data();
//     }

//     Bench::stop();
//     Bench::start("Kinect2::post_computing_color_data"sv);

//     if(color_channel_required(m_p->mode)){
//         post_computing_color_data();
//     }

//     Bench::stop();
//     Bench::start("Kinect2::post_computing_infra_data"sv);

//     if(infra_channel_required(m_p->mode) || long_infra_channel_required(m_p->mode)){
//         post_computing_infra_data();
//     }

//     Bench::stop();
//     Bench::start("Kinect2::post_computing_body_data"sv);

//     if(body_channel_required(m_p->mode)){
//         post_computing_body_data();
//     }

//     Bench::stop();
//     Bench::start("Kinect2::process"sv);

//     // processing
//     if(m_p->mode == K2FrameRequest::compressed_color_1920x1080){
//         process_compressed_color_1920x1080();
//     }else if(m_p->mode == K2FrameRequest::compressed_color_512x424){
//         process_compressed_color_512x424();
//     }else if(m_p->mode == K2FrameRequest::compressed_color_cloud ){
//         process_compressed_color_cloud();
//     }else if(m_p->mode == K2FrameRequest::compressed_color_mesh){
//         process_compressed_color_mesh();
//     }else if(m_p->mode == K2FrameRequest::depth_512x424){
//         process_depth_512x424();
//     }else if(m_p->mode == K2FrameRequest::infra_512x424 || m_p->mode == K2FrameRequest::long_exposure_infra_512x424){
//         process_infra_512x424();
//     }
//     Bench::stop();
//     Bench::start("Kinect2::release"sv);

//     // increase frame id
//     ++m_p->currentFrame;

//     // get end process timestamp
//     m_p->processedFrame->timeStampEndProcessing = std::chrono::high_resolution_clock::now().time_since_epoch().count();

//     // clean
//     clean_frame();

//     Bench::stop();

//     Bench::start("Kinect2::copy_frame"sv);
//     auto copiedFrame = m_p->processedFrame->copy_frame();
//     Bench::stop();
//     Bench::stop();

//     return std::move(copiedFrame);
// }

// K2FrameRequest K2Device::mode() const{
//     return m_p->mode;
// }

// bool K2Device::save_camera_intrisics(std::string filePath){

//     if(filePath.size() == 0){
//         return false;
//     }

//     intrinsics();

//     std::ofstream file;
//     std::string name(filePath);
//     file.open(name);
//     if(file.is_open()){
//         file << "Focal length:\n" << m_p->camIntrinsics.FocalLengthX  << " " << m_p->camIntrinsics.FocalLengthY << "\n";
//         file << "Principal point:\n" << m_p->camIntrinsics.PrincipalPointX  << " " << m_p->camIntrinsics.PrincipalPointY << "\n";
//         file << "Radial distortion:\n" << m_p->camIntrinsics.RadialDistortionSecondOrder << " " << m_p->camIntrinsics.RadialDistortionFourthOrder << " " << m_p->camIntrinsics.RadialDistortionSixthOrder  << "\n";
//     }else{
//         return false;
//     }
//     file.close();

//     return true;
// }

// bool K2Device::save_camera_space_depth_table(std::string filePath){

//     // get map table
//     if(m_p->cameraSpaceTable == nullptr){
//        delete m_p->cameraSpaceTable;
//         m_p->cameraSpaceTable = nullptr;
//     }
//     m_p->mapper->GetDepthFrameToCameraSpaceTable(&m_p->cameraSpaceTableLength, &m_p->cameraSpaceTable);

//     if(filePath.size() == 0){
//         return false;
//     }

//     std::ofstream file;
//     std::string name(filePath);
//     file.open(name);
//     if(file.is_open()){
//         for(size_t ii = 0; ii < m_p->cameraSpaceTableLength; ++ii){
//             file << m_p->cameraSpaceTable[ii].X << " " <<  m_p->cameraSpaceTable[ii].Y << "\n";
//         }
//     }else{
//         return false;
//     }
//     file.close();

//     return true;
// }

// //void Kinect2::copy_frame(Kinect2Frame *f){

// ////    m_p->swapLocker.lock();
// //    m_p->availableFrame->parameters = parameters;
// //    if(!m_p->availableFrame->copy_to(f)){
// //        Log::error("Available frame color size is 0");
// //    }
// ////    m_p->swapLocker.unlock();
// //    std::cout << "[COP2_" <<  std::this_thread::get_id() << "]";
// //}


// std::vector<float> K2Device::intrinsics() const{

//     m_p->mapper->GetDepthCameraIntrinsics(&m_p->camIntrinsics);
//     return {
//         m_p->camIntrinsics.FocalLengthX,
//         m_p->camIntrinsics.FocalLengthY,
//         m_p->camIntrinsics.PrincipalPointX,
//         m_p->camIntrinsics.PrincipalPointY,
//         m_p->camIntrinsics.RadialDistortionSecondOrder,
//         m_p->camIntrinsics.RadialDistortionFourthOrder,
//         m_p->camIntrinsics.RadialDistortionSixthOrder
//     };
// }

// void K2Device::get_color_data(){

//     Bench::start("Kinect2::get_color_data_0"sv);
//     using namespace std;

//     UINT bufferSize = 0;
//     std::uint8_t* pBuffer = nullptr;
//     m_p->colorframe->AccessRawUnderlyingBuffer( &bufferSize, &pBuffer ); // YUY2
//     m_p->colorframe->get_RelativeTime(&m_p->processedFrame->relativeTimeColor);
//     Pt4<uint8_t> *colors = reinterpret_cast<Pt4<uint8_t>*>(pBuffer);

//     Bench::stop();


//     if(depth_channel_required(m_p->mode)){

//         Bench::start("Kinect2::get_color_data_1"sv);

//         for_each(execution::par_unseq, begin(m_p->indicesDepths), end(m_p->indicesDepths), [&](size_t &id){

//             if(!is_kinect2_depth_valid((*m_p->cloudData)[id].z()) || !m_p->validityDepth2Rgb[id]){
//                 (*m_p->colorData)[id] = {0,0,0};
//                 return;
//             }

//             size_t idC = m_p->indicesDepthToColor[id];
//             if(idC%2 == 0){

//                 Pt3<uint8_t> &c1 = (*m_p->colorData)[idC];
//                 idC = idC/2;

//                 const Pt4<uint8_t> &color = colors[idC];

//                 // convert to rgb
//                 const int y0 = clamp(static_cast<int>(parameters.yFactor*color.x()), 0, 255);
//                 auto ci = 298 * (y0 - 16);

//                 const int u0 = clamp(static_cast<int>(parameters.uFactor*color.y()), 0, 255);
//                 const auto d = u0 - 128;

//                 const int v0 = clamp(static_cast<int>(parameters.vFactor*color.w()), 0, 255);
//                 const auto e = v0 - 128;

//                 c1.x() = static_cast<uint8_t>(clamp((ci + (409 * e) + 128)              >> 8, 0, 255)); // red
//                 c1.y() = static_cast<uint8_t>(clamp((ci + (-100 * d) - (208 * e) + 128) >> 8, 0, 255)); // green
//                 c1.z() = static_cast<uint8_t>(clamp((ci + (516 * d) + 128)              >> 8, 0, 255)); // blue

//             }else{
//                 Pt3<uint8_t> &c2 = (*m_p->colorData)[idC];
//                 idC = (idC-1)/2;

//                 const Pt4<uint8_t> &color = colors[idC];
//                 const int y0 = clamp(static_cast<int>(parameters.yFactor*color.x()), 0, 255);
//                 const int u0 = clamp(static_cast<int>(parameters.uFactor*color.y()), 0, 255);
//                 const int y1 = clamp(static_cast<int>(parameters.yFactor*color.z()), 0, 255);
//                 const int v0 = clamp(static_cast<int>(parameters.vFactor*color.w()), 0, 255);

//                 // convert to rgb
//                 auto c = y0 - 16;
//                 const auto d = u0 - 128;
//                 const auto e = v0 - 128;

//                 auto ci = 298 * c;
//                 const auto v1 = (516 * d) + 128;
//                 const auto v2 = (-100 * d) - (208 * e) + 128;
//                 const auto v3 = (409 * e) + 128;

//                 c = y1 - 16;
//                 ci = 298 * c;

//                 c2.x() = static_cast<uint8_t>(clamp((ci + v3) >> 8, 0, 255)); // red
//                 c2.y() = static_cast<uint8_t>(clamp((ci + v2) >> 8, 0, 255)); // green
//                 c2.z() = static_cast<uint8_t>(clamp((ci + v1) >> 8, 0, 255)); // blue
//             }
//         });

//         Bench::stop();
//     }else{

//         Bench::start("Kinect2::get_color_data_2"sv);

//         for_each(execution::par_unseq, begin(m_p->indicesRawColors), end(m_p->indicesRawColors), [&](size_t &id){
//             // get yuv
//             const Pt4<uint8_t> &color = colors[id];
//             const int y0 = clamp(static_cast<int>(parameters.yFactor*color.x()), 0, 255);
//             const int u0 = clamp(static_cast<int>(parameters.uFactor*color.y()), 0, 255);
//             const int y1 = clamp(static_cast<int>(parameters.yFactor*color.z()), 0, 255);
//             const int v0 = clamp(static_cast<int>(parameters.vFactor*color.w()), 0, 255);

//             // convert to rgb
//             auto c = y0 - 16;
//             const auto d = u0 - 128;
//             const auto e = v0 - 128;

//             const auto idC = id*2;
//             Pt3<uint8_t> &c1 = (*m_p->colorData)[idC];
//             auto ci = 298 * c;
//             const auto v1 = (516 * d) + 128;
//             const auto v2 = (-100 * d) - (208 * e) + 128;
//             const auto v3 = (409 * e) + 128;
//             c1.x() = static_cast<uint8_t>(clamp((ci + v3) >> 8, 0, 255)); // red
//             c1.y() = static_cast<uint8_t>(clamp((ci + v2) >> 8, 0, 255)); // green
//             c1.z() = static_cast<uint8_t>(clamp((ci + v1) >> 8, 0, 255)); // blue

//             c = y1 - 16;
//             ci = 298 * c;

//             Pt3<uint8_t> &c2 =  (*m_p->colorData)[idC+1];
//             c2.x() = static_cast<uint8_t>(clamp((ci + v3) >> 8, 0, 255)); // red
//             c2.y() = static_cast<uint8_t>(clamp((ci + v2) >> 8, 0, 255)); // green
//             c2.z() = static_cast<uint8_t>(clamp((ci + v1) >> 8, 0, 255)); // blue
//         });

//         Bench::stop();
//     }
// }


// bool K2Device::get_depth_data() {

//     Bench::start("Kinect2::get_depth_data_0"sv);

//     // get data
//     m_p->depthBuffer = nullptr;
//     m_p->depthFrame->AccessUnderlyingBuffer(&m_p->depthBufferSize, &m_p->depthBuffer);
//     Bench::stop();

//     int sumDepthValues = std::accumulate(m_p->depthBuffer, m_p->depthBuffer + m_p->depthBufferSize, 0);
//     if(m_p->previousSumDepthValues > 0){
//         if(sumDepthValues == m_p->previousSumDepthValues){
//             // identical frame
//             Log::error("Identical depth frame");
//             return false;
//         }
//     }
//     m_p->previousSumDepthValues = sumDepthValues;

//     Bench::start("Kinect2::get_depth_data_1"sv);

//     m_p->depthFrame->get_RelativeTime(&m_p->processedFrame->relativeTimeDepth);
//     m_p->depthFrame->get_DepthMinReliableDistance(&m_p->processedFrame->minReliableDistance);
//     m_p->depthFrame->get_DepthMaxReliableDistance(&m_p->processedFrame->maxReliableDistance);

//     Bench::stop();
//     Bench::start("Kinect2::get_depth_data_2"sv);

//     // map data
//     m_p->mapper->MapDepthFrameToCameraSpace(
//                 k2_depth_count, m_p->depthBuffer, // Depth frame data and size of depth frame
//                 k2_depth_count, reinterpret_cast<CameraSpacePoint*>(m_p->cloudData->data())); // Output CameraSpacePoint array and size

//     Bench::stop();
//     Bench::start("Kinect2::get_depth_data_3"sv);

//     m_p->mapper->MapDepthFrameToColorSpace(
//             k2_depth_count, m_p->depthBuffer, // Depth frame data and size of depth frame
//             k2_depth_count, m_p->depth2rgb.data()); // Output ColorSpacePoint array and size

//     for_each(std::execution::par_unseq, begin(m_p->indicesDepths), end(m_p->indicesDepths), [&](size_t &id){
//         const auto &m = m_p->depth2rgb[id];
//         m_p->validityDepth2Rgb[id]   = !(m.X < 0 || m.Y < 0 || m.X > k2_color_width || m.Y > k2_color_height);
//         m_p->indicesDepthToColor[id] = {static_cast<size_t>(m.X) + k2_color_width*(static_cast<size_t>(m.Y))};

//     });


//     Bench::stop();
//     return true;
// }

// void K2Device::get_infra_data(){

//     // get data
//     unsigned int size;
//     unsigned short* buffer = nullptr;
//     m_p->infraFrame->AccessUnderlyingBuffer(&size, &buffer);
//     m_p->infraFrame->get_RelativeTime(&m_p->processedFrame->relativeTimeInfra);
//     std::copy(buffer, buffer + size, std::begin(*m_p->processedFrame->infraData));
// }

// void K2Device::get_long_exposure_infra_data(){

//     // get data
//     unsigned int size;
//     unsigned short* buffer = nullptr;
//     m_p->longExposureInfraFrame->AccessUnderlyingBuffer(&size, &buffer);
//     m_p->longExposureInfraFrame->get_RelativeTime(&m_p->processedFrame->relativeTimeLongInfra);
//     std::copy(buffer, buffer + size, std::begin(*m_p->processedFrame->infraData));
// }

// void K2Device::get_body_data(){

//     Bench::start("Kinect2::get_body_data_0"sv);

//     std::array<IBody*,BODY_COUNT> bodies = {nullptr,nullptr,nullptr,nullptr,nullptr,nullptr};
//     if(!check_func_sucess(m_p->bodyFrame->GetAndRefreshBodyData(static_cast<unsigned int>(bodies.size()), bodies.data()))){
//         return;
//     }
//     m_p->bodyFrame->get_RelativeTime(&m_p->processedFrame->relativeTimeBody);

//     Bench::stop();
//     Bench::start("Kinect2::get_body_data_1"sv);

//     for (size_t ii = 0; ii < bodies.size(); ii++) {

//         auto body = bodies[ii];
//         auto &data = m_p->processedFrame->bodiesData[ii];
//         std::uint64_t trackingId = 0;
//         if(S_OK == body->get_TrackingId(&trackingId)){ // Gets the tracking ID.
//             data.id = trackingId;
//         }

//         BOOLEAN isTracked = false;
//         if(S_OK == body->get_IsTracked(&isTracked)){ // Retrieves a boolean value that indicates if the body is tracked.
//             data.tracked = isTracked;
//         }
//         BOOLEAN isRestricted = false;
//         if(S_OK == body->get_IsRestricted(&isRestricted)){ // Retrieves a boolean value that indicates if the body is restricted from a full range of motion.
//             data.restricted = isRestricted;
//         }
//         DetectionResult engaged;
//         if(S_OK == body->get_Engaged(&engaged)){ // Gets the level of user engagement.
//             data.engaged = static_cast<K2Detection>(engaged);
//         }
//         HandState leftHandState;
//         if(S_OK == body->get_HandLeftState(&leftHandState)){ // Gets the left hand state.
//             data.leftHandState = static_cast<K2HandStateT>(leftHandState);
//         }
//         TrackingConfidence leftHandConfidence;
//         if(S_OK == body->get_HandLeftConfidence(&leftHandConfidence)){ // Gets the tracking confidence for the left hand.
//             data.leftHandHightConfidence = leftHandConfidence == TrackingConfidence::TrackingConfidence_High;
//         }
//         HandState rightHandState;
//         if(S_OK == body->get_HandRightState(&rightHandState)){ // Gets the right hand state.
//             data.rightHandState = static_cast<K2HandStateT>(rightHandState);
//         }
//         TrackingConfidence rightHandConfidence;
//         if(S_OK == body->get_HandRightConfidence(&rightHandConfidence)){ // Gets the tracking confidence for the right hand.
//             data.rightHandHightConfidence = rightHandConfidence == TrackingConfidence::TrackingConfidence_High;
//         }
//         PointF lean;
//         if(S_OK == body->get_Lean(&lean)){ // Gets the amount a body is leaning, which is a number between -1 (leaning left or back) and 1 (leaning right or front)
//             data.lean = {lean.X,lean.Y};
//         }
//         TrackingState leanTracking;
//         if(S_OK == body->get_LeanTrackingState(&leanTracking)){ // Gets the lean tracking state, which indicates if the body is tracked.
//             data.leanTracking = static_cast<K2TrackingStateT>(leanTracking);
//         }

//         DWORD clippedEdges;
//         if(S_OK == body->get_ClippedEdges(&clippedEdges)){ // Gets the clipped edges.
//             // ...
//         }

//         std::array<Joint,JointType_Count> joints;
//         if(S_OK == body->GetJoints(JointType_Count, joints.data())){
//             for(auto &joint : joints){
//                 auto type = static_cast<K2BodyJointType>(joint.JointType);
//                 if(data.joints.count(type)==0){
//                     data.joints[type] = K2BodyJoint{};
//                 }
//                 data.joints[type].state = static_cast<K2TrackingStateT>(joint.TrackingState);
//                 const auto &p = joint.Position;
//                 data.joints[type].pos = {p.X,p.Y,p.Z};
//             }
//         }

//         std::array<JointOrientation,JointType_Count> jointsOrientations;
//         if(S_OK == body->GetJointOrientations(JointType_Count, jointsOrientations.data())){

//             for(auto &jointOrientation : jointsOrientations){

//                 auto type = static_cast<K2BodyJointType>(jointOrientation.JointType);
//                 if(data.joints.count(type)==0){
//                     data.joints[type] = K2BodyJoint{};
//                 }
//                 const auto &q =jointOrientation.Orientation;
//                 data.joints[type].rotQuaternion = {q.x,q.y,q.z,q.w};
//             }
//         }

//         // body->GetActivityDetectionResults() // Gets the activity detection results from IBody.
//         // body->GetAppearanceDetectionResults() // Gets the appearance.
//         // body->GetExpressionDetectionResults(); // always return null, (cross platform with xbox)
//         body->Release();
//     }

//     Bench::stop();

// //    auto d1 = std::chrono::duration_cast<std::chrono::microseconds>(t2-t1);
// //    auto d2 = std::chrono::duration_cast<std::chrono::microseconds>(t3-t2);
// //    std::cout << "get_body: " << d1.count() << " " << d2.count() <<"\n";

// //    m_p->bodyFrame->get_FloorClipPlane();
// //    m_p->bodyFrame->get_BodyFrameSource();
// }

// void K2Device::post_computing_color_data(){

//     using namespace std;

//     if(parameters.filterDepthWithColor){

//         auto &depth = *m_p->cloudData.get();
//         const auto &p = parameters;

//         for_each(execution::par_unseq, begin(m_p->indicesDepths), end(m_p->indicesDepths), [&](size_t &id){

//             if(is_kinect2_depth_valid(depth[id].z()) && m_p->validityDepth2Rgb[id]){

//                 auto color = (*m_p->colorData)[m_p->indicesDepthToColor[id]];

//                 // euclidian distance
//                 auto delta = sqrt(
//                     (color(0)-p.filterColor(0))*(color(0)-p.filterColor(0)) +
//                     (color(1)-p.filterColor(1))*(color(1)-p.filterColor(1)) +
//                     (color(2)-p.filterColor(2))*(color(2)-p.filterColor(2))
//                 );
//                 if(delta > p.maxDiffColor.x()){
//                     depth[id].z() = k2_invalid_value;
//                     return;
//                 }
//             }
//         });
//     }

// }


// void K2Device::post_computing_depth_data(){

//     using namespace std;

//     Bench::start("Kinect2::post_computing_depth_data_0"sv);



//     auto binaryDepthData       = m_p->binaryDepth.ptr();
//     auto erodedBinaryDepthData = m_p->erodedBinaryDepth.ptr();

//     for_each(execution::par_unseq, begin(m_p->indicesDepths), end(m_p->indicesDepths), [&](size_t &id){

//         auto &depth = (*m_p->cloudData)[id];

//         // reset binary mat
//         binaryDepthData[id] = 0;

//         // remove inf pts
//         if(!isnormal(depth.x()) || !isnormal(depth.y()) || !isnormal(depth.z())){
//             depth = k2_invalid_point;
//             return;
//         }

//         // width/height filter
//         const auto &id2d = m_p->indices2dDepths[id];
//         if(id2d.first < parameters.minWidth  || id2d.first > parameters.maxWidth ||  id2d.second < parameters.minHeight || id2d.second > parameters.maxHeight){
//             depth = k2_invalid_point;
//             return;
//         }

//         // depth filter
//         if(depth.z() < parameters.minDepthValue || depth.z() > parameters.maxDepthValue){
//             depth = k2_invalid_point;
//             return;
//         }

//         // binary mat
//         binaryDepthData[id] = 255;
//     });

//     Bench::stop();
//     Bench::start("Kinect2::post_computing_depth_data_1"sv);

//     // erosion
//     if(parameters.doErosion){

//         cv::Mat elementErode = cv::getStructuringElement(
//             parameters.erosionType,
//             cv::Size( 2*parameters.erosionSize + 1, 2*parameters.erosionSize+1),
//             cv::Point( parameters.erosionSize, parameters.erosionSize)
//         );
//         cv::erode( m_p->binaryDepth, m_p->erodedBinaryDepth, elementErode);

//         for_each(execution::par_unseq, begin(m_p->indicesDepths), end(m_p->indicesDepths), [&](size_t &id){

//             if(erodedBinaryDepthData[id] < parameters.minErosionValue){
//                 (*m_p->cloudData)[id].z() = k2_invalid_value;
//             }
//         });
//     }

//     Bench::stop();
//     Bench::start("Kinect2::post_computing_depth_data_2"sv);

//     // local depth
//     constexpr size_t widthPlusOne = k2_depth_width +1;
//     constexpr size_t widthMinusOne = k2_depth_width -1;

//     // neighbours number
//     const bool doMinNeighboursFiltering = parameters.minNeighboursLoops > 0;
//     if(doMinNeighboursFiltering){

//         for(size_t numLoop = 0; numLoop < parameters.minNeighboursLoops; ++numLoop){

//             for_each(execution::par_unseq, begin(m_p->indicesDepthsWithoutBorders), end(m_p->indicesDepthsWithoutBorders), [&](size_t &id){

//                 auto depth = (*m_p->cloudData)[id];
//                 const auto depthZ = depth.z();
//                 if(!is_kinect2_depth_valid(depthZ)){
//                     return;
//                 }

//                 size_t count = 0;
//                 const size_t idA = id - widthPlusOne;
//                 const size_t idB = idA + 1;
//                 const size_t idC = idB + 1;
//                 const size_t idD = id - 1;
//                 const size_t idE = id + 1;
//                 const size_t idF = id + widthMinusOne;
//                 const size_t idG = idF + 1;
//                 const size_t idH = idG + 1;

//                 if(is_kinect2_depth_valid((*m_p->cloudData)[idA].z())){
//                     ++count;
//                 }
//                 if(is_kinect2_depth_valid((*m_p->cloudData)[idB].z())){
//                     ++count;
//                 }
//                 if(is_kinect2_depth_valid((*m_p->cloudData)[idC].z())){
//                     ++count;
//                 }
//                 if(is_kinect2_depth_valid((*m_p->cloudData)[idD].z())){
//                     ++count;
//                 }
//                 if(is_kinect2_depth_valid((*m_p->cloudData)[idE].z())){
//                     ++count;
//                 }
//                 if(is_kinect2_depth_valid((*m_p->cloudData)[idF].z())){
//                     ++count;
//                 }
//                 if(is_kinect2_depth_valid((*m_p->cloudData)[idG].z())){
//                     ++count;
//                 }
//                 if(is_kinect2_depth_valid((*m_p->cloudData)[idH].z())){
//                     ++count;
//                 }

//                 m_p->depthMask[id] = count < parameters.nbMinNeighboursNb;
//             });

//             for_each(execution::par_unseq, begin(m_p->indicesDepthsWithoutBorders), end(m_p->indicesDepthsWithoutBorders), [&](size_t &id){
//                 if(m_p->depthMask[id]){
//                     (*m_p->cloudData)[id].z() = k2_invalid_value;
//                 }
//                 m_p->depthMask[id] = false;
//             });
//         }
//     }


//     Bench::stop();
//     Bench::start("Kinect2::post_computing_depth_data_3"sv);


//     const bool doLocalDiffFiltering = parameters.maxLocalDiff > 0.f;
//     if(doLocalDiffFiltering){

//         const float mLocal =  parameters.maxLocalDiff/1000.f;
//         for_each(execution::par_unseq, begin(m_p->indicesDepthsWithoutBorders), end(m_p->indicesDepthsWithoutBorders), [&](size_t &id){

//             m_p->depthMask[id] = false;

//             const auto depthZ = (*m_p->cloudData)[id].z();
//             if(!is_kinect2_depth_valid(depthZ)){
//                 return;
//             }

//             float meanDiff = 0.f;
//             size_t count = 0;
//             const size_t idA = id - widthPlusOne;
//             const size_t idB = idA + 1;
//             const size_t idC = idB + 1;
//             const size_t idD = id - 1;
//             const size_t idE = id + 1;
//             const size_t idF = id + widthMinusOne;
//             const size_t idG = idF + 1;
//             const size_t idH = idG + 1;

//             if(is_kinect2_depth_valid((*m_p->cloudData)[idA].z())){
//                 meanDiff += abs((*m_p->cloudData)[idA].z()-depthZ);
//                 ++count;
//             }
//             if(is_kinect2_depth_valid((*m_p->cloudData)[idB].z())){
//                 meanDiff += abs((*m_p->cloudData)[idB].z()-depthZ);
//                 ++count;
//             }
//             if(is_kinect2_depth_valid((*m_p->cloudData)[idC].z())){
//                 meanDiff += abs((*m_p->cloudData)[idC].z()-depthZ);
//                 ++count;
//             }
//             if(is_kinect2_depth_valid((*m_p->cloudData)[idD].z())){
//                 meanDiff += abs((*m_p->cloudData)[idD].z()-depthZ);
//                 ++count;
//             }
//             if(is_kinect2_depth_valid((*m_p->cloudData)[idE].z())){
//                 meanDiff += abs((*m_p->cloudData)[idE].z()-depthZ);
//                 ++count;
//             }
//             if(is_kinect2_depth_valid((*m_p->cloudData)[idF].z())){
//                 meanDiff += abs((*m_p->cloudData)[idF].z()-depthZ);
//                 ++count;
//             }
//             if(is_kinect2_depth_valid((*m_p->cloudData)[idG].z())){
//                 meanDiff += abs((*m_p->cloudData)[idG].z()-depthZ);
//                 ++count;
//             }
//             if(is_kinect2_depth_valid((*m_p->cloudData)[idH].z())){
//                 meanDiff += abs((*m_p->cloudData)[idH].z()-depthZ);
//                 ++count;
//             }

//             m_p->depthMask[id] = (count == 0) ? false : (meanDiff/count > mLocal);
//         });

//         for_each(execution::par_unseq, begin(m_p->indicesDepthsWithoutBorders), end(m_p->indicesDepthsWithoutBorders), [&](size_t &id){
//             if(m_p->depthMask[id]){
//                 (*m_p->cloudData)[id].z() = k2_invalid_value;
//             }
//             m_p->depthMask[id] = false;
//         });
//     }

//     Bench::stop();
//     Bench::start("Kinect2::post_computing_depth_data_4"sv);

//     if(parameters.doTemporalFilter){
//         for_each(std::execution::par_unseq, begin(m_p->indicesDepths), end(m_p->indicesDepths), [&](size_t &id){
//             if(is_kinect2_depth_valid(m_p->cloudData->at(id).z()) && is_kinect2_depth_valid(m_p->depthDataTemporal->at(id).z())){
//                 m_p->depthDataTemporal->at(id).z() = 0.5f*(m_p->cloudData->at(id).z()+m_p->depthDataTemporal->at(id).z());
//             }
//         });
//         std::swap(m_p->cloudData,m_p->depthDataTemporal);
//     }

//     Bench::stop();
//     Bench::start("Kinect2::post_computing_depth_data_5"sv);

//     if(parameters.offsetAfterMin > 0.f){
//         float min = std::numeric_limits<float>::max();
//         for_each(execution::seq, begin(m_p->indicesDepths), end(m_p->indicesDepths), [&](size_t &id){

//             const auto depthZ = (*m_p->cloudData)[id].z();
//             if(!is_kinect2_depth_valid(depthZ)){
//                 return;
//             }
//             if(depthZ < min){
//                 min = depthZ;
//             }

//         });
//         for_each(execution::par_unseq, begin(m_p->indicesDepths), end(m_p->indicesDepths), [&](size_t &id){
//             if((*m_p->cloudData)[id].z() > min + parameters.offsetAfterMin){
//                 (*m_p->cloudData)[id].z() = k2_invalid_value;
//             }
//         });
//     }


//     if(parameters.vmin > 0.f){
//         const auto squareMaxDist = parameters.vmin*parameters.vmin;
//         Pt3f mean = {};
//         size_t count = 0;
//         for_each(std::execution::unseq, begin(m_p->indicesDepths), end(m_p->indicesDepths), [&](size_t &id){

//             const auto depthZ = (*m_p->cloudData)[id].z();
//             if(!is_kinect2_depth_valid(depthZ)){
//                 return;
//             }

//             mean += (*m_p->cloudData)[id];
//             count++;
//         });
//         if(count > 0){
//             mean /= static_cast<float>(count);

//             for_each(execution::par_unseq, begin(m_p->indicesDepths), end(m_p->indicesDepths), [&](size_t &id){
//                 if(square_norm(Vec3f{geo::vec((*m_p->cloudData)[id], mean)}) > squareMaxDist){
//                     (*m_p->cloudData)[id].z() = k2_invalid_value;
//                 }
//             });
//         }
//     }

//     Bench::stop();
// }

// void K2Device::post_computing_infra_data(){

//     using namespace std;
//     uint16_t validV   = parameters.infraInvert ? 0 : 1;
//     uint16_t invalidV = parameters.infraBinary ? (parameters.infraInvert ? 1 : 0) : 0;

//     transform(execution::par_unseq, begin(*m_p->processedFrame->infraData), end(*m_p->processedFrame->infraData), begin(*m_p->processedFrame->infraData),[&](uint16_t inf){
//         if(inf < parameters.minInfra || inf > parameters.maxInfra){
//             return invalidV;
//         }else if(parameters.infraBinary){
//             return validV;
//         }
//         return inf;
//     });

//     auto minMax = minmax_element(begin(*m_p->processedFrame->infraData),end(*m_p->processedFrame->infraData));
//     auto min = (*m_p->processedFrame->infraData)[static_cast<size_t>((minMax.first - begin(*m_p->processedFrame->infraData)))];
//     auto max = (*m_p->processedFrame->infraData)[static_cast<size_t>((minMax.second - begin(*m_p->processedFrame->infraData)))];

//     auto diff = max - min;
//     if(diff==0){
//         diff = 1;
//     }

//     auto diffRange = parameters.maxInfraRange-parameters.minInfraRange;
//     auto minV = static_cast<double>(numeric_limits<uint16_t>::min());
//     auto maxV = static_cast<double>(numeric_limits<uint16_t>::max());
//     transform(execution::par_unseq, begin(*m_p->processedFrame->infraData), end(*m_p->processedFrame->infraData), begin(*m_p->processedFrame->infraData),[&](uint16_t inf){
//         return static_cast<uint16_t>(clamp<double>(((1.*inf -min)/diff)*diffRange + parameters.minInfraRange, minV, maxV));
//     });
// }

// void K2Device::post_computing_body_data(){

//     for(auto &body : m_p->processedFrame->bodiesData){
//         for(auto &joint : body.joints){
//             const auto &pos = joint.second.pos;
//             if(pos.z() < parameters.minDepthValue || pos.z() > parameters.maxDepthValue){
//                 joint.second.state = K2TrackingStateT::not_tracked;
//             }
//         }
//     }
// }

// void K2Device::process_depth_512x424(){

//     // copy depth
//     std::copy(m_p->depthBuffer, m_p->depthBuffer + m_p->depthBufferSize, m_p->processedFrame->depthData->data());

//     // reverse depth
//     for(size_t ii = 0; ii < k2_depth_height; ++ii){
//         auto *col = &(*m_p->processedFrame->depthData)[ii*k2_depth_width];
//         std::reverse(col, col + k2_depth_width-1);
//     }
// }

// void K2Device::process_infra_512x424(){
//     // reverse infra
//     for(size_t ii = 0; ii < k2_infrared_height; ++ii){
//         auto *col = &(*m_p->processedFrame->infraData)[ii*k2_infrared_width];
//         std::reverse(col, col + k2_infrared_width-1);
//     }
// }

// void K2Device::process_compressed_color_1920x1080(){

//     // reverse colors
//     for(size_t ii = 0; ii < k2_color_height; ++ii){
//         auto *col = &(*m_p->colorData)[ii*k2_color_width];
//         std::reverse(col, col + k2_color_width-1);
//     }

//     const int jpegQuality = parameters.jpegCompressionRate;
//     unsigned char *buffer = reinterpret_cast<unsigned char*>(m_p->colorData->data());
//     const int width  = k2_color_width;
//     const int height = k2_color_height;

//     // compress color (hight cost)
//     int ret = tjCompress2(m_p->jpegCompressor, buffer, width, 0, height, TJPF_RGB,
//               &m_p->tjCompressedImage, &m_p->processedFrame->jpegColorSize, TJSAMP_444, jpegQuality, TJFLAG_FASTDCT);
//     if(ret == -1){
//         Log::error(("tjCompress2 error with code: ") + std::to_string(tjGetErrorCode(m_p->jpegCompressor)));
//         return;
//     }

//     if(m_p->processedFrame->compressedImage.size() < m_p->processedFrame->jpegColorSize){
//         m_p->processedFrame->compressedImage.resize(m_p->processedFrame->jpegColorSize);
//     }
//     std::copy(m_p->tjCompressedImage, m_p->tjCompressedImage + m_p->processedFrame->jpegColorSize, std::begin(m_p->processedFrame->compressedImage));
// }

// void K2Device::process_compressed_color_512x424(){

//     std::for_each(std::execution::par_unseq, std::begin(m_p->indicesDepths), std::end(m_p->indicesDepths), [&](size_t &id){

//         if(is_kinect2_depth_valid((*m_p->cloudData)[id].z()) && m_p->validityDepth2Rgb[id]){
//             // color
// //            const auto &m = m_p->depth2rgb[id];
//             size_t idX =m_p->indicesDepthToColor[id];// {static_cast<size_t>(m.X) + kinect2_color_width*(static_cast<size_t>(m.Y))};
//             (*m_p->processedColorData)[id] = {(*m_p->colorData)[idX].x(),(*m_p->colorData)[idX].y(),(*m_p->colorData)[idX].z()};
//         }else{
//             (*m_p->processedColorData)[id] = {0,0,0};
//         }
//     });

//     // reverse colors
//     for(size_t ii = 0; ii < k2_depth_height; ++ii){
//         auto *col = &(*m_p->processedColorData)[ii*k2_depth_width];
//         std::reverse(col, col + k2_depth_width-1);
//     }

//     const int jpegQuality = parameters.jpegCompressionRate;
//     unsigned char *buffer = reinterpret_cast<unsigned char*>(m_p->processedColorData->data());
//     const int width  = k2_depth_width;
//     const int height = k2_depth_height;

//     int ret = tjCompress2(m_p->jpegCompressor, buffer, width, 0, height, TJPF_RGB,
//               &m_p->tjCompressedImage, &m_p->processedFrame->jpegColorSize, TJSAMP_444, jpegQuality, TJFLAG_FASTDCT);
//     if(ret == -1){
//         Log::error(("tjCompress2 error with code: ") + std::to_string(tjGetErrorCode(m_p->jpegCompressor)));
//         return;
//     }

//     if(m_p->processedFrame->compressedImage.size() < m_p->processedFrame->jpegColorSize){
//         m_p->processedFrame->compressedImage.resize(m_p->processedFrame->jpegColorSize);
//     }
//     std::copy(m_p->tjCompressedImage, m_p->tjCompressedImage + m_p->processedFrame->jpegColorSize, std::begin(m_p->processedFrame->compressedImage));
// }


// void K2Device::process_compressed_color_cloud(){

//     using namespace std;

//     for_each(execution::par_unseq, begin(m_p->indicesDepths), end(m_p->indicesDepths), [&](size_t &id){

//         if(is_kinect2_depth_valid((*m_p->cloudData)[id].z()) && m_p->validityDepth2Rgb[id]){
//             // color
//             const auto &m = m_p->depth2rgb[id];
//             size_t idX = {static_cast<size_t>(m.X) + k2_color_width*(static_cast<size_t>(m.Y))};
//             (*m_p->processedColorData)[id] = {(*m_p->colorData)[idX].x(),(*m_p->colorData)[idX].y(),(*m_p->colorData)[idX].z()};
//             (*m_p->processedFrame->depthData)[id] = static_cast<uint16_t>(std::clamp((*m_p->cloudData)[id].z(),0.f,8.f)*1000.f);

//         }else{
//             (*m_p->processedColorData)[id] = geo::Pt3<uint8_t>{0,0,0};
//             (*m_p->processedFrame->depthData)[id] = 0;
//         }
//     });

// //    // reverse colors
// //    for(size_t ii = 0; ii < kinect2_depth_height; ++ii){
// //        auto *col = &(*m_p->processedColorData)[ii*kinect2_depth_width];
// //        reverse(col, col + kinect2_depth_width-1);
// //    }

// //    // reverse depth
// //    for(size_t ii = 0; ii < kinect2_depth_height; ++ii){
// //        auto *d = &(*m_p->processedFrame->depthData)[ii*kinect2_depth_width];
// //        reverse(d, d + kinect2_depth_width-1);
// //    }


//     const int jpegQuality = parameters.jpegCompressionRate;
//     unsigned char *buffer = reinterpret_cast<unsigned char*>(m_p->processedColorData->data());
//     const int width  = k2_depth_width;
//     const int height = k2_depth_height;

//     int ret = tjCompress2(m_p->jpegCompressor, buffer, width, 0, height, TJPF_RGB,
//               &m_p->tjCompressedImage, &m_p->processedFrame->jpegColorSize, TJSAMP_444, jpegQuality, TJFLAG_FASTDCT);
//     if(ret == -1){
//         Log::error(("tjCompress2 error with code: ") + std::to_string(tjGetErrorCode(m_p->jpegCompressor)));
//         return;
//     }

//     if(m_p->processedFrame->compressedImage.size() < m_p->processedFrame->jpegColorSize){
//         m_p->processedFrame->compressedImage.resize(m_p->processedFrame->jpegColorSize);
//     }
//     std::copy(m_p->tjCompressedImage, m_p->tjCompressedImage + m_p->processedFrame->jpegColorSize, std::begin(m_p->processedFrame->compressedImage));

//     // compress depth integers casted in 32 bits

//     BinarySpan iData = BinarySpan{
//         reinterpret_cast<std::byte*>(m_p->processedFrame->depthData->data()),
//         k2_depth_count *2
//     };

//     // m_p->processedFrame->compressedDepthSize = m_p->depthCompressor.encode(
//     //     iData,
//     //     reinterpret_cast<uint32_t*>(m_p->processedFrame->compressedDepthData.data()), k2_depth_count/2 + 1024
//     // );
// }

// void K2Device::process_compressed_color_mesh(){

//     using namespace std;

//     for_each(std::execution::par_unseq, begin(m_p->indicesDepths), end(m_p->indicesDepths), [&](size_t &id){

//         if(is_kinect2_depth_valid((*m_p->cloudData)[id].z()) && m_p->validityDepth2Rgb[id]){
//             // color
//             const auto &m = m_p->depth2rgb[id];
//             size_t idX = {static_cast<size_t>(m.X) + k2_color_width*(static_cast<size_t>(m.Y))};
//             (*m_p->processedColorData)[id] = {(*m_p->colorData)[idX].x(),(*m_p->colorData)[idX].y(),(*m_p->colorData)[idX].z()};
//             (*m_p->processedFrame->depthData)[id] = static_cast<uint16_t>(std::clamp((*m_p->cloudData)[id].z(),0.f,8.f)*1000.f);

//         }else{
//             (*m_p->processedColorData)[id] = geo::Pt3<uint8_t>{0,0,0};
//             (*m_p->processedFrame->depthData)[id] = 0;
//         }
//     });

// //    // reverse colors
// //    for(size_t ii = 0; ii < kinect2_depth_height; ++ii){
// //        auto *col = &(*m_p->processedColorData)[ii*kinect2_depth_width];
// //        reverse(col, col + kinect2_depth_width-1);
// //    }

// //    // reverse depth
// //    for(size_t ii = 0; ii < kinect2_depth_height; ++ii){
// //        auto *d = &(*m_p->processedFrame->depthData)[ii*kinect2_depth_width];
// //        reverse(d, d + kinect2_depth_width-1);
// //    }

//     const int jpegQuality = parameters.jpegCompressionRate;
//     unsigned char *buffer= reinterpret_cast<unsigned char*>(m_p->processedColorData->data());
//     const int width  = k2_depth_width;
//     const int height = k2_depth_height;

//     int ret = tjCompress2(m_p->jpegCompressor, buffer, width, 0, height, TJPF_RGB,
//               &m_p->tjCompressedImage, &m_p->processedFrame->jpegColorSize, TJSAMP_444, jpegQuality, TJFLAG_FASTDCT);
//     if(ret == -1){
//         Log::error(("tjCompress2 error with code: ") + std::to_string(tjGetErrorCode(m_p->jpegCompressor)));
//         return;
//     }

//     if(m_p->processedFrame->compressedImage.size() < m_p->processedFrame->jpegColorSize){
//         m_p->processedFrame->compressedImage.resize(m_p->processedFrame->jpegColorSize);
//     }
//     std::copy(m_p->tjCompressedImage, m_p->tjCompressedImage + m_p->processedFrame->jpegColorSize, std::begin(m_p->processedFrame->compressedImage));

//     // // compress depth integers casted in 32 bits
//     // m_p->processedFrame->compressedDepthSize = m_p->depthCompressor.encode(
//     //     reinterpret_cast<uint32_t*>(m_p->processedFrame->depthData->data()), k2_depth_count/2,
//     //     reinterpret_cast<uint32_t*>(m_p->processedFrame->compressedDepthData.data()), k2_depth_count/2 + 1024
//     // );
// }

// void K2Device::release_color_data(){
//     if (m_p->colorframe != nullptr){
//         m_p->colorframe->Release();
//         m_p->colorframe = nullptr;
//     }
//     if (m_p->colorFrameRef != nullptr){
//         m_p->colorFrameRef->Release();
//         m_p->colorFrameRef = nullptr;
//     }
// }

// void K2Device::release_depth_data(){
//     if (m_p->depthFrame != nullptr){
//         m_p->depthFrame->Release();
//         m_p->depthFrame = nullptr;
//     }
//     if (m_p->depthFrameRef != nullptr){
//         m_p->depthFrameRef->Release();
//         m_p->depthFrameRef = nullptr;
//     }
// }

// void K2Device::release_infra_data(){
//     if (m_p->infraFrame != nullptr){
//         m_p->infraFrame->Release();
//         m_p->infraFrame = nullptr;
//     }
//     if (m_p->infraFrameRef != nullptr){
//         m_p->infraFrameRef->Release();
//         m_p->infraFrameRef = nullptr;
//     }
// }

// void K2Device::release_long_exposure_infra_data(){
//     if (m_p->longExposureInfraFrame != nullptr){
//         m_p->longExposureInfraFrame->Release();
//         m_p->longExposureInfraFrame = nullptr;
//     }
//     if (m_p->longExposureInfraFrameRef != nullptr){
//         m_p->longExposureInfraFrameRef->Release();
//         m_p->longExposureInfraFrameRef = nullptr;
//     }
// }

// void K2Device::release_body_data(){

//     if (m_p->bodyFrame != nullptr){
//         m_p->bodyFrame->Release();
//         m_p->bodyFrame = nullptr;
//     }
//     if (m_p->bodyFrameRef != nullptr){
//         m_p->bodyFrameRef->Release();
//         m_p->bodyFrameRef = nullptr;
//     }
// }

// void K2Device::release_multi_source_data(){

//     if (m_p->multiSouceFrame != nullptr){
//         m_p->multiSouceFrame->Release();
//         m_p->multiSouceFrame = nullptr;
//     }
// }

// void K2Device::clean_frame(){
//     release_depth_data();
//     release_color_data();
//     release_infra_data();
//     release_long_exposure_infra_data();
//     release_body_data();
//     release_multi_source_data();
// }




// //Pt4<float> rgb_to_hsl(const Pt4<std::uint8_t> &rgba){

// //    float H,S,L;

// //    float r = (rgba[0] / 255.0f);
// //    float g = (rgba[1] / 255.0f);
// //    float b = (rgba[2] / 255.0f);

// //    float min = std::min(std::min(r, g), b);
// //    float max = std::max(std::max(r, g), b);
// //    float delta = max - min;

// //    L = (max + min) / 2;
// //    if (almost_equal(delta,0.f)){
// //        H = 0.f;
// //        S = 0.0f;
// //    }else{
// //        S = (L <= 0.5f) ? (delta / (max + min)) : (delta / (2 - max - min));

// //        float hue;

// //        if (almost_equal(r,max)){
// //            hue = ((g - b) / 6.f) / delta;
// //        }else if (almost_equal(g,max)){
// //            hue = (1.0f / 3) + ((b - r) / 6.f) / delta;
// //        }
// //        else{
// //            hue = (2.0f / 3.f) + ((r - g) / 6.f) / delta;
// //        }

// //        if (hue < 0.f){
// //            hue += 1.f;
// //        }
// //        if (hue > 1.f){
// //            hue -= 1.f;
// //        }

// //        H = hue * 360.f;
// //    }
// //    return Pt4<float>{H,S,L,1.f*rgba.w()};
// //}

// //float hue_to_rgb(float v1, float v2, float vH) {

// //    if (vH < 0.f){
// //        vH += 1.f;
// //    }

// //    if (vH > 1.f){
// //        vH -= 1.f;
// //    }

// //    if ((6.f * vH) < 1.f){
// //        return (v1 + (v2 - v1) * 6.f * vH);
// //    }

// //    if ((2.f * vH) < 1.f){
// //        return v2;
// //    }

// //    if ((3.f * vH) < 2.f){
// //        return (v1 + (v2 - v1) * ((2.0f / 3.f) - vH) * 6.f);
// //    }

// //    return v1;
// //}

// //Pt4<std::uint8_t> hsl_to_rgb(Pt4<float> hsva){

// //    float H = hsva.x();
// //    float S = hsva.y();
// //    float L = hsva.z();

// //    if (almost_equal(S,0.f)){
// //        auto v = static_cast<std::uint8_t>(L * 255.f);
// //        return Pt4<std::uint8_t>{v,v,v,static_cast<std::uint8_t>(hsva.w())};
// //    }else{
// //        float v1, v2;
// //        float hue = H / 360.f;

// //        v2 = (L < 0.5f) ? (L * (1 + S)) : ((L + S) - (L * S));
// //        v1 = 2 * L - v2;

// //        return Pt4<std::uint8_t>{static_cast<std::uint8_t>(255 * hue_to_rgb(v1, v2, hue + (1.0f / 3.f))),
// //                        static_cast<std::uint8_t>(255 * hue_to_rgb(v1, v2, hue)),
// //                        static_cast<std::uint8_t>(255 * hue_to_rgb(v1, v2, hue - (1.0f / 3.f))),static_cast<std::uint8_t>(hsva.w())};
// //    }
// //}



// //void Kinect2::process_color_1920x1080(){
// //    // reverse colors
// //    for(size_t ii = 0; ii < kinect2_color_height; ++ii){
// //        auto *col = &(*colorData)[ii*kinect2_color_width];
// //        std::reverse(col, col + kinect2_color_width-1);
// //    }
// //}

// //void Kinect2::process_color_512x424(){

// //    std::for_each(std::execution::par_unseq, std::begin(m_p->indicesDepths), std::end(m_p->indicesDepths), [&](size_t &id){

// //        if(!m_p->validityDepth2Rgb[id]){
// //            (*processedColorData)[id] = {0,0,0,255};
// //        }else{
// //            // color
// //            const auto &m = m_p->depth2rgb[id];
// //            size_t idX = {static_cast<size_t>(m.X) + kinect2_color_width*(static_cast<size_t>(m.Y))};
// //            (*processedColorData)[id] = {(*colorData)[idX].x(),(*colorData)[idX].y(),(*colorData)[idX].z(), 255};
// //        }
// //    });

// //    // reverse colors
// //    for(size_t ii = 0; ii < kinect2_depth_height; ++ii){
// //        auto *col = &(*processedColorData)[ii*kinect2_depth_width];
// //        std::reverse(col, col + kinect2_depth_width-1);
// //    }
// //}

// //void Kinect2::process_cloud(){


// //    currentCloudSize = 0;
// //    std::for_each(std::execution::seq, std::begin(m_p->indicesDepths), std::end(m_p->indicesDepths), [&](size_t &id){

// //        if(is_kinect2_depth_valid((*cloudData)[id].z()) && m_p->validityDepth2Rgb[id]){
// //            // pos
// //            (*processedCloudData)[currentCloudSize] = (*cloudData)[id];
// //            // color
// //            const auto &m = m_p->depth2rgb[id];
// //            size_t idx = (static_cast<unsigned int>(m.X)) + kinect2_color_width*(static_cast<unsigned int>(m.Y));
// //            (*processedColorData)[currentCloudSize] = (*colorData)[idx];
// //            // cloud size
// //            currentCloudSize++;
// //        }else{
// //            // color
// //            (*processedColorData)[currentCloudSize] = {0,0,0,255};
// //        }
// //    });
// //}

// //void Kinect2::process_mesh(){

// //    std::uint32_t idT = 0;
// //    currentCloudSize = 0;
// //    std::for_each(std::execution::seq, std::begin(m_p->indicesDepths), std::end(m_p->indicesDepths), [&](size_t &id){
// //        if(is_kinect2_depth_valid((*cloudData)[id].z()) && m_p->validityDepth2Rgb[id]){

// //            // pos
// //            (*processedCloudData)[currentCloudSize] = (*cloudData)[id];
// //            // color
// //            const auto &m = m_p->depth2rgb[id];
// //            size_t idx = (static_cast<unsigned int>(m.X)) + kinect2_color_width*(static_cast<unsigned int>(m.Y));
// //            (*processedColorData)[currentCloudSize] = (*colorData)[idx];
// //            // cloud size
// //            currentCloudSize++;
// //            // triangle id validity
// //            m_p->validIdPerPointMesh[id] = idT++;
// //        }else{
// //            // color
// //            (*processedColorData)[id] = {0,0,0,255};
// //            // triangle id validity
// //            m_p->validIdPerPointMesh[id] = idT;
// //        }
// //    });

// //    idT = 0;
// //    for(std::uint32_t ii = 0; ii < kinect2_depth_width-1; ++ii){
// //        for(std::uint32_t jj = 0; jj < kinect2_depth_height-1; ++jj){

// //            const std::uint32_t idTopLeft     = jj*kinect2_depth_width+ii;
// //            const std::uint32_t idTopRight    = (jj)*kinect2_depth_width+(ii+1);
// //            const std::uint32_t idBottomLeft  = (jj+1)*kinect2_depth_width+(ii);
// //            const std::uint32_t idBottomRight = (jj+1)*kinect2_depth_width+(ii+1);

// //            const bool idTopLeftValid       = is_kinect2_depth_valid((*cloudData)[idTopLeft].z())     && m_p->validityDepth2Rgb[idTopLeft];
// //            const bool idTopRightValid      = is_kinect2_depth_valid((*cloudData)[idTopRight].z())    && m_p->validityDepth2Rgb[idTopRight];
// //            const bool idBottomLeftValid    = is_kinect2_depth_valid((*cloudData)[idBottomLeft].z())  && m_p->validityDepth2Rgb[idBottomLeft];
// //            const bool idBottomRightValid   = is_kinect2_depth_valid((*cloudData)[idBottomRight].z()) && m_p->validityDepth2Rgb[idBottomRight];

// //            int invalidCount = (idTopLeftValid? 1 : 0) + (idTopRightValid? 1 : 0) + (idBottomLeftValid? 1 : 0) + (idBottomRightValid? 1 : 0);
// //            if(invalidCount < 3){
// //                continue;
// //            }

// //            if(invalidCount == 4){
// //                if(std::abs((*cloudData)[idTopLeft].z()-(*cloudData)[idBottomRight].z()) < std::abs((*cloudData)[idTopRight].z()-(*cloudData)[idBottomLeft].z())){
// //                    (*processedtrianglesData)[idT++] = Pt3<std::uint32_t>{m_p->validIdPerPointMesh[idTopLeft],
// //                                                                  m_p->validIdPerPointMesh[idBottomRight],
// //                                                                  m_p->validIdPerPointMesh[idBottomLeft]};
// //                    (*processedtrianglesData)[idT++] = Pt3<std::uint32_t>{m_p->validIdPerPointMesh[idTopLeft],
// //                                                                  m_p->validIdPerPointMesh[idTopRight],
// //                                                                  m_p->validIdPerPointMesh[idBottomRight]};
// //                }else{
// //                    (*processedtrianglesData)[idT++] = Pt3<std::uint32_t>{m_p->validIdPerPointMesh[idTopLeft],
// //                                                                  m_p->validIdPerPointMesh[idTopRight],
// //                                                                  m_p->validIdPerPointMesh[idBottomLeft]};
// //                    (*processedtrianglesData)[idT++] = Pt3<std::uint32_t>{m_p->validIdPerPointMesh[idTopRight],
// //                                                                  m_p->validIdPerPointMesh[idBottomRight],
// //                                                                  m_p->validIdPerPointMesh[idBottomLeft]};
// //                }
// //                continue;
// //            }

// //            if(!idTopLeftValid){
// //                (*processedtrianglesData)[idT++] = Pt3<std::uint32_t>{m_p->validIdPerPointMesh[idTopRight],
// //                                                              m_p->validIdPerPointMesh[idBottomRight],
// //                                                              m_p->validIdPerPointMesh[idBottomLeft]};
// //            }
// //            if(!idTopRightValid){
// //                (*processedtrianglesData)[idT++] = Pt3<std::uint32_t>{m_p->validIdPerPointMesh[idTopLeft],
// //                                                              m_p->validIdPerPointMesh[idBottomRight],
// //                                                              m_p->validIdPerPointMesh[idBottomLeft]};
// //            }
// //            if(!idBottomLeftValid){
// //                (*processedtrianglesData)[idT++] = Pt3<std::uint32_t>{m_p->validIdPerPointMesh[idTopLeft],
// //                                                              m_p->validIdPerPointMesh[idTopRight],
// //                                                              m_p->validIdPerPointMesh[idBottomRight]};
// //            }
// //            if(!idBottomRightValid){
// //                (*processedtrianglesData)[idT++] = Pt3<std::uint32_t>{m_p->validIdPerPointMesh[idTopLeft],
// //                                                              m_p->validIdPerPointMesh[idTopRight],
// //                                                            m_p->validIdPerPointMesh[idBottomLeft]};
// //            }
// //        }
// //    }

// //}

